<!DOCTYPE html>
<html lang="fr">
<head>
<meta charset="utf-8"/>
<title> recap exam gprog 2021-2022 </title>
<style>
body {
	background: rgb(32,32,32);
	color: white;
	font-family: Arial, Helvetica, sans-serif;
	--dark: 1;
}
img:not(.modal-content) {
	border-style: solid;
	border-width: 1px;
	border-color: black;
	height: 100px;
	cursor: pointer;
	/*transition: 0.3s;*/
}
img:not(.modal-content):hover {opacity: 0.7;}
pre {
	font-size: 16.5px;
	tab-size: 8;
	font-family: Arial, Helvetica, sans-serif;
}

.collapsible {
  background-color: #777;
  color: white;
  cursor: pointer;
  padding: 18px;
  /*width: 50%;*/
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}
.active, .collapsible:hover {
  background-color: #555;
}
.content {
  /*padding: 0 18px;*/
  display: none;
  /*overflow: auto;*/
  width: 200%;
  background-color: rgb(64,64,64);
  color: white;
}

/* The Modal (background) */
.modal {
  /*align: center;*/
  display: none; /* Hidden by default */
  position: fixed; /* Stay in place */
  z-index: 1; /* Sit on top */
  padding-top: 100px;
  left: 0;
  top: 0;
  width: 100%; /* Full width */
  height: 100%; /* Full height */
  overflow: auto; /* Enable scroll if needed */
  background-color: rgb(0,0,0); /* Fallback color */
  background-color: rgba(0,0,0,0.9); /* Black w/ opacity */
}

/* Modal Content (image) */
.modal-content {
  margin: auto;
  display: block;
  /*scale: 500%;*/
  max-width: 70%;
  max-height: 70%;
}

/* Caption of Modal Image */
#modalCaption {
  margin: auto;
  display: block;
  width: 90%;
  /*max-width: 700px;*/
  text-align: center;
  color: #ccc;
  padding: 10px 0;
  height: 150px;
}

</style>
</head>
<body id="body"> <!-- ////////////////////////////////////////////// -->
<!--<h1> A </h1>

<ul>
	<li> a </li>
	<li> 
		<ul>
			<li> a </li>
			<li> b </li>
		</ul> 
	</li>
</ul>-->
<!--<script>
	function darkmode() 
	{ 
		if(document.getElementById("body").style.dark == 1)
		{
			document.getElementById("body").style.backgroundColor = "rgb(256,256,256)";
			document.getElementById("body").style.color = "rgb(0,0,0)";
			document.getElementById("body").style.dark = "0";
		}
		else 
		{
			document.getElementById("body").style.backgroundColor = "rgb(32,32,32)";
			document.getElementById("body").style.color = 'white';
			document.getElementById("body").style.dark = "1";
		}
	}
</script>
 <button type="button" onclick="darkmode();" style="float: right;">Toggle Dark Mode</button> -->
<!-- The Modal -->

<div id="myModal" class="modal">
  <img class="modal-content" id="modalImg" src="empty.png" alt=" ">
  <!-- <div id="caption"></div> -->
</div>

<h1>Recap Programmation Graphique</h1>
<pre>
	Les infos sur cette page sont à destination à la fois du cours de prog graphique des game progs et de math1 des game artists.

	La priorité c'est d'écrire les sections utiles pour vos projets de construction de shaders pour l'examen, donc : 
		-les bases du workflow de production de shaders :
			-ShaderGraph
			-ShaderLab
		-les exemples qu'on a vu : 
			-textures
			-luminosité
			-animation
			-transparence
			-éclairage direct
			-outlines
			-dithering
			-eau
		-comment faire une vidéo
		
	Si il y a des sections dédiées Game Prog ou Game Art, elles auront respectivement un fond bleu (GP), ou vert (GA).
</pre>
<h2>Ressources</h2><pre>
	disponibles sur drive ou par demande via mail / discord.

	datant de 2021-2022
		-graph prog 
			-dossier drive "Graph Prog B3GP 2021-22"
				-assets
				-bibliographie du cours de graph prog
		-math1 
			-dossier drive "Math1 B2GA 2021-22"
				-recap minimal de cours seulement, incomplet
		-math2
			-dossier drive "Math2 B3GA 2021-22"
				-assets
				-screenshots
				-recap minimal de cours seulement, incomplet
	datant de 2019-2021
		-math1 B3 2019-2020 
			-dossier drive "Shadergraph B3GA 2019-2020"
				-docs écrits (obsolètes avec des erreurs)
				-assets
				-screenshots
		-math1 B2 2019-2021
			-dossier drive "Shadergraph B2GA"
				-google site
				-vidéos de cours, assez courtes (intro manquante)
				-assets
				-screenshots
			-VODs youtube de cours complètes de math1 2020-2021
		-animation procédurale 2019-2021
			-dossier drive "Proc Anim"
				-google site
					recap minimal de cours seulement, incomplet
				-assets
				-screenshots
			-VODs youtube de cours complètes d'animation procédurale 2020-2021
		-level design procédural B3 2020-2021
			-dossier drive "Proc LD B3 2020-2021"
				-google site 
					-bibliographie
					-recap minimal de cours seulement, incomplet
				-projet + guide d'utilisation
			
</pre><h2>Versions de Unity</h2><pre>
	La version actuelle des cours se passe sur 2021.1
	
	Pipeline de rendu built-in (BIRP) vs URP vs HDRP
		//todo : blabla intro présentation
			
		On travaille avec URP parce que HDRP fonctionne pas sur mobile.
			
</pre>
<h2>Le rendu et les shaders, définitions</h2>
<pre>
	Le rendu consiste à obtenir l'image d'une scène du point de vue d'une caméra.
		Mais on peut aussi faire le rendu d'objets individuels.
	Les images sont des grilles de pixels, où chaque pixel a une valeur exprimée en rgb.
	Le rendu est effectué par une série de calculs à partir des données de notre scène.
	Cette série d'étapes de calculs c'est ce qu'on appelle le pipeline graphique.

	Scènes et objets
		-Pour simplifier, on suppose généralement qu'une scène est une liste d'objets visibles,
		et que les objets sont des listes de triangles.
		-À leur tour les triangles sont un trio de vertices qui ont des propriétés:
			-position
			-normale
			-UVs
			-tangente
			-vertex color
	
	Render loop
		Pour faire le rendu d'une scène en temps réel, typiquement on calcule plusieurs images par seconde, typiquement 60 par seconde, 
		mais ça dépend de la fréquence d'affichage de l'écran, on a souvent 120fps de nos jours par exemple.		
		
		-(Le cycle de raffraichissement de l'écran)
			<button type="button" class="collapsible">[détails techniques] +</button>
			<div class="content">
			60 fois par seconde, notre moteur graphique va calculer une image constituée de pixels, et envoyer ça à l'écran pour l'afficher.
			
			En fait, en mémoire, l'image est une liste avec des valeurs numériques pour les couleurs tous les pixels de l'image.
			Cette liste doit être remplie avec ces valeurs de couleurs, et une fois que la liste est remplie, on peut l'envoyer à l'écran par le câble depuis la carte graphique.
			Sauf que si le rendu prend trop longtemps,
			le temps qu'il faut pour calculer chaque image peut prendre plus longtemps que l'intervalle de temps disponible avant l'affichage par l'écran de l'image suivante, et on affiche des images moins souvent que 60 fois par seconde.

			Et là on a deux possibilités:
				-Soit avoir de la synchro verticale (VSync), 
				ce qui veut dire attendre qu'une image soit finie avant de l'afficher à l'écran, ce qui veut dire garder l'image précédente à l'écran en attendant que la nouvelle arrive.
				-Soit ne pas avoir de vsync, 
				ce qui veut dire envoyer l'image actuellement entre train d'être rendue même si elle est incomplète, 
				ce qui permet d'avoir au moins la moitié de l'image mise à jour, mais ça crée un artefact graphique appelé une "tear line" (ligne de déchirure) typiquement horizontale au milieu de l'écran.
				
			En fait en interne, quand on est en train de faire le rendu d'une image, la liste des valeurs des pixels part dans une zone mémoire appelée le back buffer, 
			et l'image qui est actuellement affichée à l'écran est stockée dans une zone appelée le front buffer au cas où on a besoin de l'envoyer à l'écran plusieurs fois. 
			Et ce qui se passe quand on affiche une nouvelle image à l'écran, c'est qu'on inverse le front et le back buffer, 
			c'est à dire qu'en fait on a deux zones mémoires A et B qui sont utilisées en alternance pour stocker l'image en cours de rendu, et l'image en cours d'affichage.
			</div>
		-Draw calls
			Ce qui est envoyé dans le pipeline de rendu c'est typiquement une liste de vertices, qui vont constituer nos triangles. 
			Ils peuvent aussi consistuer d'autres types de primitives, comme des lignes, des éventails de triangles, mais on va pas s'y intéresser. 
			Ces vertices sont donnés au pipeline avec leurs propriétés (position dans la scène, UVs, normales, etc.). 
			À chaque fois qu'on envoie des vertices dans le pipeline, ça s'appelle un draw call, parce qu'en interne, le moteur appelle la fonction Draw(), qui prend nos vertices et les passe à la carte graphique.
			-Batching
				Pour des raisons de performance, on a tendance à grouper les vertices qui ont le même material, pour les envoyer dans le pipeline en même temps, même si ces vertices appartiennent à des meshs différents. 
				On appelle ça le batching ("batch" veut dire "fournée" en anglais, comme faire des cookies au four). 
				Ça permet de réduire le nombre de draw calls.
					Ça améliore les performances parce qu'à chaque draw call il faut reconfigurer le pipeline en chargeant un nouveau shader, des nouvelles textures, changer divers paramètres de rendus, entre autres.
		
		-(Forward Rendering vs Deferred Rendering)			
			<button type="button" class="collapsible">[détails techniques] +</button>
			<div class="content">
			C'est bon de savoir de quoi il retourne quand on parle des méthodes de forward et de deferred rendering,
			parce que parfois on a des problèmes qui sont causés par ces méthodes, 
			mais c'est pas le plus prioritaire non plus donc vous pouvez ignorer si vous êtes fatigué.es.
			Je vais brutalement simplifier l'explication, mais donc :
			
			La méthode naïve pour organiser le rendu des objets,
			c'est de faire le rendu des objets un par un,
			et pour chaque objet, de prendre les contributions de chaque lumière, une par une,
			ce qui fait par exemple, que pour 30 objets et 30 lumières, on a 30x30 == 900 "étapes de rendu".
			C'est ce qu'on appelle le Forward Rendering.
			
			Il existe une façon d'accélérer le rendu, appelé le Deferred Rendering (rendu différé, où on diffère l'application des lumières jusqu'à la fin du processus de rendu),
			où on commence en fait par "fusionner" tous les objets de la scène en 1 objet qui couvre tout l'écran.
			Cette fusion prend la forme d'un pré-rendu de la scène, stocké dans une texture appelée un G-buffer.
			Et une fois les objets fusionnés en 1, quand on veut appliquer les lumières, 
			on a plus que 1x30 == 30 "étapes de rendu", vu que les lumières s'appliquent à 1 seul objet.
			En fait on a 30+30 == 60 étapes de rendu parce que la fusion nécessite de faire le tour de tous les objets au départ, mais 60 c'est beaucoup plus rapide que 900 en tout cas.
			Cependant, le deferred rendering ne permet pas de bien gérer les objets transparents (pas aussi faciles à fusionner), 
			donc ceux-là sont toujours rendus avec la logique du forward rendering. 
			Ça complexifie aussi l'anti-aliasing, et d'autres détails.
			</div>
	
	Pipelines fixes vs programmables
		Anciennement, les pipelines étaient configurables, mais pas programmables, et donc on avait pas beaucoup de flexibilité dans le déroulement du rendu. 
		De nos jours on a l'option d'insérer des scripts dans le pipeline de rendu pour contrôler certaines étapes.
		La dernière console à avoir un pipeline fixe était la Wii (2006).
		Ces scripts qui permettent de contrôler le rendu de nos objets, on appelle ça des shaders.
		
	Shaders		
		Les shaders permettent typiquement contrôler la forme des objets, leur éclairage, couleur et transparence. Vertex par vertex, mais aussi pixel par pixel.
		-familles de shaders
			On peut regrouper les shaders courants en plusieurs familles:
				-shaders de debug
					On a parfois besoin d'afficher les données de nos objets pour les vérifier (positions, vecteurs, UVs, résultats de calculs intermédiaires, etc.), et on peut parfois les afficher sous forme de couleur par exemple.
					Ces shaders servent surtout pendant le dev, et pas dans le build final.
					<img src="./debug.png" alt="debug" onclick="zoompic(event)">
				-shaders "réalistes" old-school/retro (donc par si réalistes que ça de nos jours).
					<img src="./flat.png" alt="flat" onclick="zoompic(event)">
				-shaders réalistes modernes, qui suivent le principe du Physically-Based Rendering (PBR)
					On a pas tellement besoin d'apprendre à en faire nous-mêmes de cette catégorie,
					c'est à ça que sert le shader de material standard de unity.
					<img src="./pbr.png" alt="pbr" onclick="zoompic(event)">
				-shaders non-réalistes, souvent stylisés, cartoon, dits NPR (Non-Photo-Realistic)
					<img src="./cartoon.png" alt="cartoon" onclick="zoompic(event)">
				-autres shaders, souvent pour des effets particuliers.
					<img src="./fx.png" alt="fx" onclick="zoompic(event)">
		
		-Materials
			Si un shader est un script qui sert à contrôler le rendu d'un material,
			alors le material fait faire le rendu par le shader, en lui disant quelles valeurs utiliser.
			Les materials eux-mêmes contiennent donc 2 informations:
				-quel shader le material utilise pour être rendu
				-une liste de valeurs de paramètres à donner à ce shader pour le rendu
			Exemple:
				un champ de force peut avoir un look calculé par un shader,
				mais on peut avoir plusieurs variantes de champ de force, avec des propriétés différentes:
					-l'un peut être bleu
					-un autre rouge avec des textures différentes
					-un autre noir avec des options supplémentaires
				et ces trois variantes peuvent être trois materials différents,
				qui utilisent tous le même shader de champ de force,
				mais chacun aura des valeurs différentes pour la couleur, les textures, etc.
		
		-Exemples d'applications courantes
			Nature et magie élémentaires :
				Feu, flammes, explosions, lave, lumière
					<img src="./feu.png" alt="feu" onclick="zoompic(event)">	<img src="./nuke.png" alt="nuke" onclick="zoompic(event)">
				Eau, bulles, caustiques, cascades, acide
					<img src="./cascade.png" alt="cascade" onclick="zoompic(event)">
				Vent et fantômes, fumée, magie ombre
					<img src="./storm.png" alt="storm" onclick="zoompic(event)">
				Glace, neige
					<img src="./ice.png" alt="ice" onclick="zoompic(event)">
				Électricité, éclairs
					<img src="./bolt.png" alt="bolt" onclick="zoompic(event)">
				Herbe
				Cristaux et roches, sable
					<img src="./sand.png" alt="sand" onclick="zoompic(event)">	<img src="./crystal.png" alt="crystal" onclick="zoompic(event)">
			Science & Fiction :
				Champs de force
					<img src="./shield.png" alt="shield" onclick="zoompic(event)">
				Portails, Téléporteurs
					<img src="./portal.png" alt="portal" onclick="zoompic(event)">
				Hologrammes et invisibilité
				Lasers
				Désintégration
			Styles :
				Cel-shading et cartoon
					<img src="./cel_shading.png" alt="cel_shading" onclick="zoompic(event)">
				Contours
					<img src="./outline.jpg" alt="outline" onclick="zoompic(event)">
				Dithering & pixel-art auto
					<img src="./obra_dinn.png" alt="obra_dinn" onclick="zoompic(event)">
				Filtres : palettes couleur, négatifs, etc.
					<img src="./visor.jpg" alt="visor" onclick="zoompic(event)">
			Catégories spéciales :
				Effets volumétriques (light shafts, fumée, brouillard, nuages, ...)
				Intégration (traces dans le sable ou la neige, flammes enveloppantes, éclairs)
				Particules
				Rendu multi-passe (voir au travers des murs, contours doux, ...)
				Post-processing (profondeur de champ, bloom, tone-mapping, ...)
		
		-Quelques tutoriels ShaderGraph Populaires de 2019
			Brackeys
				<a href="https://www.youtube.com/watch?v=KGGB5LFEejg">HOLOGRAM using Unity Shader Graph</a>
				<a href="https://www.youtube.com/watch?v=NiOGWZXBg4Y">FORCE FIELD in Unity - SHADER GRAPH</a>
				<a href="https://www.youtube.com/watch?v=taMp1g1pBeE">DISSOLVE using Unity Shader Graph</a>
				
			Gabriel Aguiar Prod.
				<a href="https://www.youtube.com/watch?v=hTJqo1HeEOs">Unity Shader Graph - Shield Effect Tutorial</a>
				<a href="https://www.youtube.com/watch?v=yJ0NRr-DdYU">Unity Shader Graph - Waterfall Effect Tutorial</a>
				<a href="https://www.youtube.com/watch?v=glSsaRpHKos">Unity Shader Graph - Fire Flames Shader Tutorial</a>
				<a href="https://www.youtube.com/watch?v=28MQrE7fUk4">Unity Shader Graph - Nuke Explosion Effect Tutorial</a>
				<a href="https://www.youtube.com/watch?v=w0znZIuvQ2I">Unity Shader Graph - Portal Shader Tutorial</a>
				<a href="https://www.youtube.com/watch?v=Qyh9RPxeKcA">Unity Shader Graph - Tornado Shader Effect Tutorial</a>
				<a href="https://www.youtube.com/watch?v=u9lOaPVtSqg">Unity Shader Graph - Electricity Shader Effect Tutorial</a>
				<a href="https://www.youtube.com/watch?v=mGd3nYXj1Oc">Unity Shader Graph - Laser Beam Tutorial</a>

			Binary Impact
				<a href="https://www.youtube.com/watch?v=rlGNbq5p5CQ">Unity Shadergraph Tutorial - Cracked Ice</a>			

			Code Monkey
				<a href="https://www.youtube.com/watch?v=6AKR4b4C5j">Shield Force Field - Shader Graph Tutorial</a>

			AE Tuts
				<a href="https://www.youtube.com/watch?v=IzvKGsdByFk">Water ball explosion using shader graph Unity 3D</a>
				<a href="https://www.youtube.com/watch?v=nhYrtvT543w">Water fountain using shader graph (part ½)</a>
				<a href="https://www.youtube.com/watch?v=EELbMlnOzQE">Glass/Water Refractive Shader in Unity using Shader Graph</a>

			PolyToots
				<a href="https://www.youtube.com/watch?v=WdxBJVCBr_A">Unity Shader Graph: Crystals!</a>
				<a href="https://www.youtube.com/watch?v=r1yrkZn1owg&t=524s">[Part 2] Burning + Dissolve Shader in Unity.</a>

	
</pre>
<h2>Les étapes du render pipeline</h2>
<button type="button" class="collapsible">[incomplet] +</button>
<div class="content">
<pre>
	
	-Vertex properties
		-position
		-normales
		-tangentes
		-UVs
		-vertex color
		-...
	-(Gestion de topologie - Hull shaders / Domain shaders / Geometry shaders)
	-Vertex shading
		-Projection
			-Espaces / repères 3D
				-ex: Héliocentrisme vs Géocentrisme
				-Origines
				-Axes
					-Conventions
						-Y vertical vs Z vertical
						-Profondeur avec Z+ ou Z-
							-Handedness / repères main-gauche vs main-droite
				-Object Space
					-Origine/Pivot vs Centre
					-Objet vs Géométrie
					-Parenting
				-World Space
				-View Space
				-Clip Space
					-Camera
						-Planes
							-Near
							-Far
							-Left, Right, Top, Bottom
						-Types de projection
							-Perspective
							-Orthographique
							-Autres
								-...
						-Projection
							-Théorème de Thalès
							-Matrices (cf plus loin)
				-Screen Space
					en fait la projection entre clip et screen space est faite pendant la rasterization
			
			-Transforms
				-Ré-exprimer un vecteur dans un autre repère
				-Appliquer des transforms
					-Translation
					-Rotation
					-Scaling
					-(Shearing)
					-Projection
				-Matrices
					-Signification et Construction
						-Dans notre case, on liste les vecteurs qui sont les axes d'un espace
					-Multiplication
						-Aide visuelle
						-Opérations
						-Piège avec l'ordre des termes
						-Avoir le même nombre de colonnes à gauche que de lignes à droite
				-Matrices de transformation
					-Piège de la contravariance
					-Inverser des matrices
						-Résolution d'équations
						-Manuellement
							-Inverser la translation
							-Transposer la rotation
					-Transposer des matrices
				-Vecteurs position vs Vecteurs direction
					-Coordonnées Homogènes W						
	-Rasterization
		-Clip space -> Screen space
		-test d'inclusion de pixel dans un triangle
			-coordonnées barycentriques
				-calcul d'aires de sous-triangles
					-cross product / produit vectoriel
			-détection d'aires "négatives"
		-interpolation barycentrique de propriétés de vertices pour chaque fragment de la surface d'un triangle
	-Fragment shading
		-Couleur
			-Textures
			-Lumière
		-Transparence
			-Textures
			-Type de shader (Opaque, Opaque avec AlphaClip, Transparent)
			-Type de blending (Alpha blend, Additif, Multiplication, ...)
		-Propriétés PBR
			-Smoothness/Roughness
			-Metalness
			-Emission
		-Tri
			-Depth Testing
	-Merging
		-combinaison des fragments pour obtenir la couleur finale des pixels
	
</pre>
</div>
<h2>ShaderGraph</h2><pre>
	La construction de shaders, c’est le cas d'usage principal des maths et de la logique en game art, 
	c'est pourquoi le cours de maths de game art se concentre sur l'apprentissage de shadergraph.
	<h3>	Installation</h3>
		Pour avoir un projet unity avec shadergraph installé dedans, on a deux options :
		
		soit 1) Création de projet Unity avec le template URP, normalement ça setup tout correctement par défaut
			<img src="./creation_projet_template_urp.png" alt="creation_projet_template_urp" onclick="zoompic(event)">
		
		soit 2) Installer à la main 		
			<button type="button" class="collapsible">[optionel] +</button>
		<div class="content">
			-Package manager accessible via Window > Package Manager
				-Les packages sont pas tous listés au même endroit, vérifier dans Unity Registry
					<img src="./package_manager_dropdown1.png" alt="package_manager_dropdown1" onclick="zoompic(event)">				
				-Installer:
					-Core RP Library						
					-Universal RP
					-Shader Graph
						<img src="./package_manager_srp_install.PNG" alt="package_manager_srp_install" onclick="zoompic(event)"> <img src="./package_manager_urp_and_sg_install.PNG" alt="package_manager_urp_and_sg_install" onclick="zoompic(event)">		
			-Asset de pipeline
				-Créer via Assets > Create > Rendering > Universal Render Pipeline > Pipeline Asset
				-Donner au projet via Edit > Project Setting > Graphics > le premier champ
					<img src="./set_pipeline_in_graphics.png" alt="set_pipeline_in_graphics" onclick="zoompic(event)">
				-Setup la Opaque Texture et la Depth Texture
					-sur le Pipeline Asset, cocher Depth Texture et Opaque Texture
						<img src="./opaque_and_depth_tex.PNG" alt="opaque_and_depth_tex" onclick="zoompic(event)">
						-ça sera nécessaire pour faire fonctionner les nodes Scene Color et Scene Depth, mais aussi pour faire fonctionner 
							sampler2D _CameraOpaqueTexture;
							sampler2D _CameraDepthTexture;
						-Dans un projet à template URP, on a un Pipeline Asset déjà créé, il s'appelle UniversalRP-HighQuality
			-Update les materials
				-si tout est rose après avoir mis le nouveau pipeline, c'est normal, il faut changer les matériaux pour qu'ils utilisent des shaders compatibles avec le pipeline choisi
					<img src="./everything_magenta.PNG" alt="everything_magenta" onclick="zoompic(event)">
				-l'option est dans Edit > Render Pipeline > Universal Render Pipeline > Upgrade Project Materials to UniversalRP Materials
				     <img src="./upgrade_mats.png" alt="upgrade_mats" onclick="zoompic(event)">
				-sinon manuellement créer des nouveaux materials pour les différents objets et les ré-attribuer à la main sur les gameobjects.
		</div>
		+Créer une nouvelle scène vide et travailler dedans
			-des fois la scène par défaut peut interférer avec ce qu'on fait
	
	<h3>	Workflow de création de shader</h3>
		-Créer Asset > Shader > Universal Render Pipeline > Unlit Shader Graph
			<img src="./create_sg_asset.png" alt="create_sg_asset" onclick="zoompic(event)">
		-Ouvrir le shader avec un double clic sur l'asset
		-Faire des modifs dans le shader			
		-Save Asset
			-en haut à gauche de la fenêtre de shadergraph
				<img src="./change_sg.PNG" alt="change_sg" onclick="zoompic(event)">
		-Créer un Material
			-Soit séparement via Assets > Create > Material
				-puis drag l'asset shader sur l'asset material
					<img src="./drag_sg_to_mat.PNG" alt="drag_sg_to_mat" onclick="zoompic(event)">
			-(Soit en créant à partir de clic droit sur l'asset shader)
		-Placer le material sur un game object
			-avec un drag and drop ça marche
				<img src="./drag_mat_to_go.PNG" alt="drag_mat_to_go" onclick="zoompic(event)">
		-Cocher Always Refresh pour les shaders animés
			<img src="./always_refresh.png" alt="always_refresh" onclick="zoompic(event)">
	
	<h3>	Interface</h3>
		-Naviguer à la souris
			-clic molette pour déplacer la vue
		
		-Main Preview
			<img src="./sg_preview.PNG" alt="sg_preview" onclick="zoompic(event)">
			-clic droit dessus pour choisir sur quel mesh prévisualiser le shader
			-Ça casse facilement, certains shaders pourront pas être prévisualisés correctement
				-le look du shader qui compte vraiment c'est celui dans la scène.
		
		-Master Stack (anciennement master node)
			<img src="./sg_master.PNG" alt="sg_master" onclick="zoompic(event)">
			La master stack contient une liste de champs de propriétés qui décrivent le look du material auquel est appliqué le shader, pour chaque point à la surface des objets qui ont ce material. 
			Le shader aura des nodes qui feront des calculs, et les résultats finaux de ces calculs seront raccordés à ces champs via des cables.
			Il y a deux types de "points" à la surface des objets: les vertices, qui sont les sommets du mesh de l'objet, et les fragments, qui sont plus ou moins les pixels de l'objet visibles à l'écran.
			-Section Vertex
				La section Vertex de la master stack permet en gros de déplacer les vertices du mesh pour le déformer, et d'ajuster les normales et les tangentes pour les garder cohérentes avec la déformation.
			-Section Fragment				
				La section Fragment de la master stack permet de définir la couleur, transparence et l'éclairage pour chaque pixel visible de notre objet.
			Comme on en est qu'à l'introduction du cours, pour l'instant on va juste dire que le champ Base Color permet de choisir la couleur de base du material. Les autres champs seront expliqués au cours des exemples plus loin.
			Si on met rien dans ces champs, des valeurs par défaut seront utilisées.			
		
		-Graph Inspector<table><tr><td style="height: 450px; vertical-align: top;">
			<img src="./sg_inspector.PNG" alt="sg_inspector" onclick="zoompic(event)">					
			Le graph inspector permet de régler des paramètres importants du shadergraph.
			On peut pour l'instant ignorer l'onglet "node settings" en haut, 
			et aussi ignorer les champs Precision et Target Settings.
			Les paramètres importants sont dans la section en dessous intitulée "Universal":
				-le champ Material permet de décider si le shader subit l'éclairage (Lit) ou non (Unlit).
				-le champ workflow permet de choisir entre le mode moderne PBR Metallic, 
				ou l'ancien mode Specular qui permet de contrôler la couleur des réflexions séparément.
				-le champ Surface permet de décider si le shader est de type Opaque ou Transparent.
					-choisir l'option Transparent ajoute un champ Alpha à la master stack pour contrôler l'opacité
					-certains nodes ne fonctionneront qu'en mode Transparent (Scene Color par exemple).
				-la checkbox Alpha Clip nous permet de faire un shader de cut-out, même si le shader est en mode Opaque
					-cocher cette option ajoute un champ Alpha et Alpha Clip Threshold à la master stack
						-ce Alpha Clip Threshold (seuil de découpage alpha) permet de
						rendre tous les pixels avec une opacité sous ce seuil totalement transparents
				-la checkbox Two-Sided permet de faire render les faces arrières ou internes (backfaces) des meshs
				-les autres options sont ignorables pour l'instant </td> 
				<td><img src="./graph_inspector.PNG" alt="graph_inspector" onclick="zoompic(event)" style="height: 400px; vertical-align: bottom;">
				</td>
				</tr>
			</table>
			
				
		<button type="button" class="collapsible">[vu plus loin] +</button>
		<div class="content">
		-Blackboard & properties externes
			<img src="./sg_blackboard.PNG" alt="sg_blackboard" onclick="zoompic(event)">
			//todo
			-Valeurs par défaut
				//todo
				-Piège de priorité
					//todo
			-Name vs Reference
				//todo
			//todo
		
		-Ports et cables
			//todo
			-nombre de cases
				//todo
			-Vecteurs XYZ, RGB
				//todo
		
		-Créer des nodes
			-Espace
			-Clic droit > Create node		
		</div>
</pre><h2>ShaderLab</h2><pre>
	//todo
	
	<h3>	Workflow de création de shader</h3>
		//todo
		-pipeline built-in (BIRP) vs URP vs HDRP
			//todo
			//todo poster le lien vers le template URP
	
	<h3>	Structure des fichiers</h3>
		//todo
		
	<h3>	API et docs</h3>
		//todo	

</pre><!-- <h2>Shaders de debug</h2><pre>
	//todo
	-node Position
		//todo
	-node UV
		//todo
	-node Normal Vector
		//todo
	-node Screen Position
		//todo
	-node Vertex Color
		//todo
	//todo

</pre> --><h2>Warning pour les vidéos ci-dessous</h2><pre>
	Les vidéos datent de 2019 pour la plupart donc:
		-l'interface est un peu différente
			-master node au lieu de master stack dans shader graph
			-les options du shader sont situées dans le graph inspector au lieu de l'icone engrenage du node master maintenant
			-les options des propriétés du blackboard ne sont plus listées sous les propriétés elles-mêmes,
				mais dans l'onglet node settings du panneau graph inspector
			-...
		-certains soucis abordés n'existent plus
			-souci avec la différence entre nom de property et référence de property dans le blackboard
			-performances de l'interface quand on anime via la fenêtre animation
			-...
		-certains nodes fonctionnent différemment
			-flipbook
				-modulo automatique
				-arrondi automatique
			-...
		-...
</pre><h2>Texturing</h2><pre>
	<!-- <a href="https://drive.google.com/file/d/1zMz4b5UO-ccquYR11yXr2dO9rliBPMgJ/view?usp=sharing">lien drive</a>
	vs 
	embed youtube: -->
	<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/R799a0IIucM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
		0:00 - intro + workflow
			-la vidéo va parler de texture sampling (échantillonnage de texture)
			-c'est un recap d'un cours en présentiel précédent (de 2019)
			-création de shadergraph+material
				-menu différent, de nous jours les shadergraphs sont listés sous Assets > Create > Shader > Universal Render Pipeline
			-application de shader sur objet
			-ouverture de shadergraph
		1:08 - importer des textures
			-via drag and drop depuis la fenêtre project vers la fenêtre shader graph
			-node Sample Texture 2D
				-son port de sortie RGBA peut être raccordé au champ Base Color du master
			-on peut changer quelle texture est samplée par le champ sélecteur du port d'entrée Texture2D
			-on peut créer un node Texture 2D Asset séparé pour distribuer la même texture vers plusieurs nodes Sample Texture 2D
		2:58 - blackboard
			-on peut donner une texture au shader via les Properties
				-elles sont crées dans le menu Blackboard
					-via le gros bouton +
				-on peut drag and drop une property de type Texture2D dans le graphe
					-et refiler ça au node Sample Texture2D
				-les Properties sont faites pour être visibles/exposées dans l'éditeur de Unity
					-y'a un -PIEGE-, c'est la valeur donnée à la property dans l'éditeur de unity qui a la priorité
						-et pas une éventuelle valeur par défaut choisie dans le shadergraph lui-même
		5:04 - UVs
			-Sample Texture 2D utilise les UVs par défaut du mesh par défaut si on lui raccorde pas d'UVs particulières
			-par exemple on peut raccorder un node Tiling & Offset au champ UV de Sample Texture2D
				-Tiling & Offset permet de faire répéter la texture via le tiling
				-ça peut décaler la texture via l'offset
			-si on veut faire scroll une texture dans le temps, on peut raccorder un node Time (time) dans le champ Offset de Tiling & Offset
				-Quand on alimente des champs qui réclament N champs avec des cables qui viennent de nodes qui donnent 1 champ
					-ça copie la 1 valeur dans chacun des N champs
					-et c'est pour ça que si on met time dans Offset, ça met time dans x et time dans y, et donc ça bouge en diagonale
			-Time c'est le nombre de secondes depuis le début de la scène
				-0 secondes, 0.5s, 1s, 1.24s, etc.
			-Le node twirl permet de déformer les textures en mode tourbillon
			-Le node rotate permet de faire tourner des UVs
			-Le node polar coordinates est pas expliqué dans ce cours
		9:20 - sampler states
			-on peut raccorder un node Sampler State dans le champ Sampler du node Sample Texture 2D
			-ça permet de contrôler le mode de filtrage de la texture
				-point filtering / nearest, ça donne des texels visibles carrés, cf le look de minecraft
				-linear filtering / bilinear, ça donne des texels lissés en faisant une moyenne des 4 texels les plus proches pour chaque fragment de notre objet
				-trilinear c'est mieux que bilinear, mais ça se voit à peine
			-le wrap mode ça détermine comment le sampling se comporte quand on sort de l'espace UV
				-repeat ça fait se répéter la texture telle quelle quand on atteint le bord
				-clamp empêche les UVs de dépasser l'intervalle [0;1]
					-et donc quand on observe en dehors de l'intervalle 01 avec clamp, on voit le dernier texel sur le bord se répéter
				-mirror ça fait se répéter la texture mais en mode pingpong / miroir
				-mirror once ça fait se répéter la texture une fois et ensuite ça clamp
		13:57 - normal maps
			-le paramètre Type de Sample Texture 2D:
				-Default c'est pour sampler des textures couleur
				-Normal c'est pour sampler des normal maps spécifiquement
			-le paramètre Space c'est pour les normal maps
				-par défaut les normal maps sont exprimées en tangent space
					-d'où le fait que le champ soit réglé sur Tangent par défaut
					-c'est les normal maps sur fond bleu/violet habituelles
				-l'option Object c'est pour les normal maps en object-space
					-mais c'est plus rare
					//todo insert screenshot			
		16:18 - conflit entre clamp et scrolling
			-essayer de faire scroll une texture qui est en wrapmode clamp, ça casse le scrolling et tiling
		17:09 - problème de Time
			-Si vous avez besoin de reset la valeur de Time, vous pouvez lancer/relancer puis arrêter votre scène
		18:50 - problème d'animation qui joue pas dans la vue Scène
			-(en 2019)parfois les shaders s'animent pas même si Always Refresh est coché
				-y'a des manips relou faisables [...]
		20:22 - problème de Preview
			-ignorer les previews cassés, certains shaders /ne peuvent pas/ être preview correctement
				-regarder le résultat dans la scène directement
		21:03 - problème de cutout transparent
			-les textures qui sont opaques d'un côté, transparent de l'autre, et qui sont en wrapmode repeat et en filtermode linear/trilinear, peuvent avoir des lignes moches qui se forment autour des bords transparents
				//todo mettre screenshot
				-les lignes apparaissent pas avec le wrapmode en clamp, ou le filtermode en nearest
				-la raison pour laquelle ça se produit c'est qu'en filtermode linear les fragments au bord de l'objet vont avoir une couleur/transparence qui est une moyenne des 4 texels voisins, 
				mais sur le bord, les texels voisins sont en dehors de l'espace UV, 
				et donc si on est en wrapmode, ça va aller chercher les texels de l'autre côté de la texture, qui sont opaques,
				donc nos fragments sur le bord ont une transparence qui est une moyenne entre des texels transparents et des texels opaques sont ils seront *un peu* opaques,
				et donc pas totalement transparents
			-les wrapmode et filtermode sont aussi réglables sur les options d'importation sur l'asset lui-même
		25:30 - outro 
			-recap des sujets vus ^	
	
</pre><h2>Couleur et Luminosité</h2><pre>
	-Dans les shaders, les couleurs sont représentées en rgb avec des nombres à virgule, compris entre 0 et 1.
		-par exemple le gris moyen a les valeurs rgb -> (0.5, 0.5, 0.5)
		-et le blanc a pour valeur (1, 1, 1)
	
	-Quand on multiplie des couleurs entre elles (ou des vecteurs, de façon plus générale)
		//todo add screenshot
		-ça se fait canal par canal
			-càd qu'on multiplie le rouge avec le rouge, le vert avec le vert, et le bleu avec le bleu
				-rgba1 * rgba2 = (r1 * r2, g1 * g2, b1 * b2, a1 * a2)
			-ou dans le cas de vecteurs xyz, on multiplie de la même façon et on obtient (x1 * x2, y1 * y2, z1 * z2)
		-le node multiply s'adapte au nombre de cases qu'on lui fournit en entrée
			de telle façon à ce que les deux choses qu'on multiplie aient bien le même nombre de cases
		//todo expliquer les types de données de base de shadergraph, les cables et les ports
	
	-différence entre valeurs linéaires et valeurs couleur avec correction gamma
		<button type="button" class="collapsible">[incomplet, basse priorité] +</button>
		<div class="content">
		-shader graph fait la distinction entre les valeurs couleur
			et les valeurs non-couleur, dites "linéaires".
		-les valeurs linéaires sont des valeurs qui augmentent en ligne droite
			-par exemple on peut compter des photons, c'est une mesure objective,
				-et on peut avoir N photons, ou 2N photons, etc.
		-à l'inverse, notre perception n'est pas linéaire
			-donc ça rend les calculs plus compliqués
		-le problème c'est qu'on voit trop bien dans le noir
		<img src="./Linear-vs-gamma-corrected.png" alt=" " onclick="zoompic(event)">
		-ça fait que si on traitait des palettes de gris avec des valeurs équilibrées,
		on les verrait déséquilibrées, avec trop de gris clair et pas assez de noirs
		-on compense en assombrissant nos valeurs de luminosité
		-on assombrit le contraste de nos valeurs avec une puissance (au sens mathématique, donc x², etc.)
		-c'est cette variable puissance qu'on appelle gamma
		-le standard sRGB utilise une puissance de 0.45 pour appliquer l'encodage gamma
		-et puissance 2.2 pour appliquer le décodage gamma
		-x puissance 2.2 donne des valeurs plus sombres, càd plus basses, 
			-parce que nos valeurs viennent de l'intervalle entre 0 et 1.
			-les puissances ont l'effet inverse sur des valeurs entre 0 et 1.
		-par contre, y'a une subtilité pas évidente du tout:
			-quand on enregistre un fichier avec des couleurs, c'est enregistré plus clair (encodé avec gamma à 0.45)
			-pour que les valeurs sombres à l'origine occupent dans la palette la place des gris clairs, ce qui permet de préserver les valeurs sombres
			-quand on veut lire un fichier avec des couleurs dedans, on décode
			-le décodage ré-assombrit les valeurs avec gamma à 2.2
		</div>
	-HDR
		<button type="button" class="collapsible">[incomplet, basse priorité] +</button>
		<div class="content">
		HDR veut dire "high dynamic range", ou "haute gamme dynamique" en français.
			Ça s'oppose au LDR (low dynamic range), qui est l'encodage typique de couleurs.
			En LDR, on a 256 niveau de luminosité possibles par canal couleur.
			En fait, cette limite de 256 intervient surtout au niveau de l'affichage final sur l'écran.
			En vrai, tant qu'on est dans l'ordinateur, on fait ce qu'on veut avec les valeurs.
			L'idée du HDR c'est d'artificiellement augmenter la quantité de valeurs de luminosité représentables.
			Ça fait ça en nous permettant de représenter des valeurs de luminosité hors de l'intervalle [0;1].
			L'idée c'est de se donner la possibilité de distinguer entre des valeurs très brillantes mais d'intensité différente.
			Une lampe peut briller blanc, un phare peut briller blanc, et le soleil peut briller blanc.
			Mais c'est 3 valeurs de blanc avec des luminosités différentes.
			En LDR, les 3 étant blanches, elles auraient une valeur de (1,1,1) (par défaut).
			En HDR, on peut dire que la lampe a une valeur de 1, le phare de 10, le soleil de 100.
			Et ensuite, une courbe de tone-mapping rammène ces valeurs dans l'intervalle [0;1].
			On peut appliquer une logique similaire aux valeurs sombres.
			On veut pouvoir représenter des valeurs sombres de 0.1, 0.01, 0.001, etc.
			La courbe de tone-mapping applatit en fait nos valeurs moyennes pour faire de la place aux valeurs sombres et claires.
			L'idée c'est de réduire le contraste de tout pour gagner de la marge de manoeuvre.
			//todo add courbe
			//todo finir d'expliquer
		-tone-mapping
			-ACES
				//todo
		</div>
	

</pre><h2>Animations</h2><pre>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/bUzLpvbZZaU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
		0:00 - intro
		1:00 - nodes de textures procédurales
		2:45 - couleur via multiply
		3:45 - luminosité via multiply
		4:14 - propriétés
		5:46 - contraste
		10:40 - sin(time)
		11:08 - node remap
		12:35 - appliquer les variations via multiply
		13:50 - outro
		14:04 - node hue (teinte)

	//todo
	-Textures procédurales
		-node Checkerboard
			//todo
		-node Simple noise / Gradient noise
			//todo
		-node Voronoi
			//todo
	-node Time
		//todo
		-float precision
			//todo
			-video minecraft
				//todo
	-Scrolling UVs
		//todo
	-Luminosité et contraste
		//todo
		-Multiply
			//todo
		-Power
			//todo
	-Contrôle externe
		//todo
		-Depuis la fenêtre animation
			<iframe width="560" height="315" src="https://www.youtube.com/embed/FB3prTz6CJE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
				0:00 - intro
				1:38 - la fenêtre animation
				2:27 - nom vs référence de propriété
				5:48 - animation via keyframes et courbes
				9:42 - souci de performance de l’interface
			//todo
		-Depuis un script
			//todo
	-Texture flipbook
		<iframe width="560" height="315" src="https://www.youtube.com/embed/B6pC-Ay3hqo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			0:00 - intro
			1:20 - posterize
			3:40 - reimplem posterize avec floor
			6:08 - pourquoi ceiling est pas mieux que floor/posterize
			6:49 - round
			7:30 - factorisation
			9:44 - outro
			
		<iframe width="560" height="315" src="https://www.youtube.com/embed/IfAhmEvvMYM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			0:00 intro
			0:30 qu'est-ce qu'un flipbook
			1:37 récupérer la texture depuis le site de unity
			2:28 textures HDR
			3:00 setup
			3:51 node flipbook
			5:27 indices de tiles (time*60)
			9:42 floor
			10:31 Time est instable
			12:55 reset de Time
			15:05 QA AAA
			15:58 ?
			16:43 invert xy
			18:00 modulo
			22:14 alpha
			23:15 correction de boucle
			24:37 outro
		//todo
		
</pre><h2>Éclairage direct</h2><pre>
	//todo
	-Phong shading
		//todo
		-éclairage oldschool
			//todo
		-Réflexions diffuses
			//todo
			-dot product / produit scalaire
				//todo
		-Réflexions spéculaires
			//todo
		-Réflexions ambiantes
			//todo
	-Ombres
		//todo
	-Lumières multiples
		//todo
	//todo
		
</pre><h2>Cel Shading</h2><pre>
	//todo
	-exemples
		-Zelda WindWaker
			//todo
		-DBZ Budokai
			//todo
	-Posterization
		//todo
		-node Posterize
			//todo
		-Manuellement
			//todo
			-Floor()
				//todo
			-Ceil()
				//todo
			-Round()
				//todo
	//todo
			
</pre><h2>Outlines</h2><pre>
	//todo
	-exemples
		-Okami
			//todo
	-Rendu multipasses
		//todo
	-Vertex Displacement
		//todo
		-Normales lissées vs éclatement des faces
			//todo
			-Cas des meshs à facettes apparentes
				//todo
		-compenser pour la perspective
			//todo
	-masquer les front faces
		//todo
		-node IsFrontFace
			//todo
		-node Branch
			//todo
	-afficher les backfaces
		//todo
		-Cull Front dans ShaderLab
			//todo
		-Two-Sided dans ShaderGraph
			//todo
	//todo
		
</pre><h2>Dithering</h2><pre>
	//todo
	
</pre><h2>Eau</h2><pre>
	//todo
	-sur le Pipeline Asset, cocher Depth Texture et Opaque Texture
		-ça sera nécessaire pour faire fonctionner les nodes 
			-Scene Color 
			-Scene Depth, 
		mais aussi pour faire fonctionner 
			sampler2D _CameraOpaqueTexture;
			sampler2D _CameraDepthTexture;
	-Reflection probes
		//todo
	-Refraction
		-Opaque Texture / node Scene Color
			//todo
		//todo
	-Absorption
		-Depth Texture / node Scene Depth
			//todo
		//todo
	-Vertex Displacement
		//todo
	//todo
</pre><h2>Faire une vidéo</h2><pre>
	-vidéo avec OBS et recorder
		<iframe width="560" height="315" src="https://www.youtube.com/embed/oB5DHcYDf9M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			00:00 - Unity Recorder (13 minutes) - Essayez déjà ça avant de passer à la suite
			13:10 - OBS Studio (19 minutes)
			32:30 - Trouble-shooting OBS (5minutes)
		
	-vidéo top qualité sur machine basses-perfs
		<iframe width="560" height="315" src="https://www.youtube.com/embed/jfC-LEbHdJs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</pre>
<script>

// Get the modal
var modal = document.getElementById("myModal");

// Get the image and insert it inside the modal - use its "alt" text as a caption
var modalImg = document.getElementById("modalImg");
var modalCaption = document.getElementById("caption");

function zoompic(event)
{
	modal.style.display = "block";
  	modalImg.src = event.target.src;
	modalImg.width = event.target.naturalWidth;
	modalImg.height = event.target.naturalHeight;
  	modalCaption.innerHTML = event.target.alt;
}

modal.onclick = function() { 
  modal.style.display = "none";
}

var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
<!--<h2> B2 </h2>
<pre>
b
	b
	b
	
	<img src="./az.PNG" alt=" "> <img src="./ae.PNG" alt=" ">  <img src="./ar.PNG" alt=" "> 
	
</pre>		-->
</body>
</html>
